# Rename this file to .env and fill in your details

# LLM Provider Selection
LLM_PROVIDER="openai"  # Options: "openai", "ollama", or "lmstudio"

# OpenAI Configuration (if using LLM_PROVIDER="openai")
OPENAI_API_KEY="sk-your_openai_api_key_here"
# OPENAI_API_BASE="your_custom_llm_api_base_url"
OPENAI_MODEL="gpt-4o-mini-2024-07-18"

# Ollama Configuration (if using LLM_PROVIDER="ollama")
OLLAMA_MODEL="llama3.2:3b"  # Or any installed Ollama model
OLLAMA_HOST="http://localhost:11434"  # Default Ollama endpoint

# LM Studio Configuration (if using LLM_PROVIDER="lmstudio")
LMSTUDIO_HOST="http://localhost:1234/v1"  # LM Studio OpenAI-compatible endpoint
LMSTUDIO_MODEL="mlx-community/Qwen2.5-7B-Instruct-4bit"  # Default MLX model
LMSTUDIO_VISION_MODEL="mlx-community/Qwen2.5-VL-3B-Instruct-4bit"  # Vision model
LMSTUDIO_EMBEDDING_MODEL="nomic-ai/nomic-embed-text-v1.5-GGUF"  # Embedding model
LMSTUDIO_MAX_TOKENS="2048"  # Maximum tokens for generation
LMSTUDIO_CONTEXT_LENGTH="32768"  # Model context window

# PostgreSQL Storage Configuration
ENABLE_POSTGRES_STORAGE="false"  # Set to "true" to enable PostgreSQL storage
POSTGRES_CONNECTION="postgresql://user:password@localhost:5432/bates_documents"
POSTGRES_POOL_SIZE="5"  # Number of connections in the pool
STORE_PAGE_LEVEL_TEXT="true"  # Store individual page text in addition to full document